# app.py
import os
import time
import re
import csv
from datetime import datetime

import streamlit as st

# --- External deps used by your existing project ---
# RAG (your existing builder)
from src.rag.rag_chain import get_rag_qa

# Fine-tune (optional: will load if present)
try:
    from src.finetune.finetune_wrapper import load_finetuned_model, get_finetuned_answer
    FT_AVAILABLE = True
except Exception:
    FT_AVAILABLE = False

LOG_FILE = "query_logs.csv"



# ----------------------------- Helpers -----------------------------
def normalize_rag_return(rag_ret):
    """
    Accept any shape returned by get_rag_qa():
      - chain
      - (chain, vector_store)
      - (chain, vector_store, ...)
    Return: (chain, vector_store or None)
    """
    chain = None
    vector_store = None

    # Single object (not tuple/list)
    if hasattr(rag_ret, "invoke"):
        return rag_ret, None

    # Tuple/list: search for pieces
    if isinstance(rag_ret, (tuple, list)):
        for item in rag_ret:
            if chain is None and hasattr(item, "invoke"):
                chain = item
            # Best-effort detection for a vector store-like object
            if vector_store is None and (
                hasattr(item, "similarity_search_with_score") or hasattr(item, "similarity_search")
            ):
                vector_store = item
    return chain, vector_store


def extract_value_only(text: str) -> str:
    """
    Post-process the answer to keep only the value(s), preserving currency/units/percent if present.
    If multiple matches, return the longest token (usually includes unit).
    """
    s = (text or "").strip()

    # If chain said Not found, keep that
    if s.lower().startswith("not found"):
        return "Not found"

    # Remove spaces *inside* numbers like "1 237 138"
    s = re.sub(r"(?<=\d)\s+(?=\d)", "", s)
    # Normalize weird double commas
    s = re.sub(r",+", ",", s)

    # Pattern: currency? number with commas/decimals, optional unit/percent
    pattern = re.compile(
        r"([$Â£â‚¬]?\s?\d{1,3}(?:,\d{3})*(?:\.\d+)?\s?(?:million|billion|thousand|m|bn|k)?%?)",
        re.IGNORECASE,
    )
    matches = [m.strip() for m in pattern.findall(s) if m.strip()]

    # Also allow plain percentages like "12 %" / "12%"
    pct = re.findall(r"\d+(?:\.\d+)?\s?%", s)
    matches.extend([p.replace(" ", "") for p in pct])

    # Fallback: plain number
    if not matches:
        plain = re.findall(r"\d{1,3}(?:,\d{3})*(?:\.\d+)?", s)
        matches.extend(plain)

    if matches:
        # Choose the longest (usually includes units/currency)
        candidate = max(matches, key=len)
        # Remove space between currency and number if any
        candidate = re.sub(r"^\s*([$Â£â‚¬])\s+", r"\1", candidate)
        return candidate

    # If nothing matched, return original (already strict prompt should avoid prose)
    return s or "Not found"


def score_to_conf(score):
    """
    Convert FAISS score to confidence.
    If score is similarity (higher is better), use directly.
    If score is distance (lower is better), invert.
    """
    try:
        if score is None:
            return None
        score = float(score)
        # Heuristic: if score > 1, treat as distance
        if score > 1.0:
            return 1.0 / (1.0 + score)
        else:
            return max(0.0, min(score, 1.0))  # Clamp similarity to [0,1]
    except Exception:
        return None


def color_for_conf(c):
    if c is None:
        return "gray"
    if c >= 0.70:
        return "green"
    if c >= 0.40:
        return "orange"
    return "red"


def infer_page_number(doc):
    """Try hard to find a page number from Document metadata or content."""
    meta = getattr(doc, "metadata", {}) or {}

    for key in ("page", "page_number", "page_num"):
        if key in meta and meta[key] not in (None, ""):
            try:
                p = int(meta[key])
                # Many loaders are 0-based; prefer human-friendly page >= 1
                return p + 1 if p == 0 else p
            except Exception:
                pass

    # LangChain's PyPDF sometimes nests under 'loc': {'page': int}
    if "loc" in meta and isinstance(meta["loc"], dict) and meta["loc"].get("page") is not None:
        try:
            p = int(meta["loc"]["page"])
            return p + 1 if p == 0 else p
        except Exception:
            pass

    # Last resort: look for "Page 7" text near the start
    content = getattr(doc, "page_content", "") or ""
    m = re.search(r"\b[Pp]age\s+(\d{1,3})\b", content[:400])
    if m:
        return int(m.group(1))

    return None


def ensure_log_header(path):
    if not os.path.exists(path):
        with open(path, mode="w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Question", "Method", "Answer", "Confidence", "Time (s)", "Correct (Y/N)"])


# ------------------------ Cached loaders ------------------------
@st.cache_resource
def load_rag():
    rag_ret = get_rag_qa()
    chain, vstore = normalize_rag_return(rag_ret)
    return chain, vstore


@st.cache_resource
def load_ft():
    if not FT_AVAILABLE:
        return None, None
    try:
        return load_finetuned_model()
    except Exception:
        return None, None


# ----------------------------- UI -----------------------------
st.set_page_config(page_title="Financial QA â€“ RAG vs Fine-Tune", layout="wide")
st.title("ðŸ“Š Financial Statements Q&A â€” RAG vs Fine-Tune")
st.caption("Answer format: **values only** (keep currency/units/percent).")

# Method choice
method = st.radio("Select method:", ["RAG", "Fine-Tuned"], horizontal=True)

# Question entry
question = st.text_input("Ask a question about the financial statements:")

# State container for latest run
if "last" not in st.session_state:
    st.session_state.last = None  # dict with keys: question, method, answer, conf, time_s, sources


# --------------- Primary action: Get Answer (triggers inference only on click) ---------------
colA, colB = st.columns([1, 1])
with colA:
    run_btn = st.button("Get Answer", type="primary")

# Placeholder for outputs (answer + meta + sources)
answer_box = st.empty()
meta_box = st.empty()
sources_box = st.container()

# Run only when button clicked
if run_btn:
    if not question.strip():
        st.warning("Please enter a question first.")
    else:
        start = time.time()

        # RAG mode
        if method == "RAG":
            rag_chain, vstore = load_rag()
            if rag_chain is None:
                st.error("RAG chain failed to load. Please check your RAG setup.")
            else:
                # Best-effort: prefetch top docs with scores for a confidence estimate
                top_docs_with_scores = []
                if vstore is not None and hasattr(vstore, "similarity_search_with_score"):
                    try:
                        top_docs_with_scores = vstore.similarity_search_with_score(question, k=6)
                    except Exception:
                        top_docs_with_scores = []

                # Invoke the chain with the correct input key
                # Always pass raw question string
                resp = rag_chain.invoke(question)


                # Extract answer
                raw_answer = resp["result"] if isinstance(resp, dict) and "result" in resp else str(resp)
                answer_value = extract_value_only(raw_answer)

                # Confidence (avg of top-2)
                conf_vals = []
                for _, sc in top_docs_with_scores[:5]:
                    conf = score_to_conf(sc)
                    if conf is not None:
                        conf_vals.append(conf)
                confidence = round(sum(conf_vals) / len(conf_vals), 4) if conf_vals else None

                # Sources
                source_docs = []
                if isinstance(resp, dict) and "source_documents" in resp and resp["source_documents"]:
                    source_docs = resp["source_documents"]
                elif top_docs_with_scores:
                    source_docs = [d for d, _ in top_docs_with_scores[:3]]

                elapsed = time.time() - start

                # Save in session_state for "Mark Correctness"
                st.session_state.last = {
                    "question": question,
                    "method": method,
                    "answer": answer_value,
                    "confidence": confidence,
                    "time_s": round(elapsed, 2),
                    "sources": source_docs[:5],
                }

        # Fine-Tuned mode
        else:
            ft_model, ft_tok = load_ft()
            if ft_model is None:
                st.error("Fine-tuned model not available in this environment.")
                st.session_state.last = None
            else:
                ans = get_finetuned_answer(ft_model, ft_tok, question)
                answer_value = extract_value_only(ans)
                elapsed = time.time() - start

                st.session_state.last = {
                    "question": question,
                    "method": method,
                    "answer": answer_value,
                    "confidence": None,  # set if your FT wrapper can return a probability
                    "time_s": round(elapsed, 2),
                    "sources": [],  # no sources in FT
                }

# ----------------- Show results (only after Get Answer) -----------------
if st.session_state.last:
    last = st.session_state.last

    answer_box.subheader("Answer")
    answer_box.success(last["answer"])

    # Meta info
    conf_txt = "â€”" if last["confidence"] is None else f"{last['confidence']:.4f}"
    conf_color = color_for_conf(last["confidence"])
    meta_box.markdown(
        f"**Retrieval Confidence Score:** "
        f"<span style='color:{conf_color}; font-weight:600'>{conf_txt}</span><br>"
        f"**Method Used:** {last['method']}<br>"
        f"**Response Time:** {last['time_s']:.2f} seconds",
        unsafe_allow_html=True,
    )

    # Sources (RAG)
    if last["method"] == "RAG":
        with sources_box:
            st.subheader("Sources")
            if not last["sources"]:
                st.caption("No sources returned.")
            else:
                for i, doc in enumerate(last["sources"], start=1):
                    page = infer_page_number(doc)
                    page_label = f"Page {page}" if page else "Page â€”"
                    src_name = None
                    meta = getattr(doc, "metadata", {}) or {}
                    # Try a friendly name if present
                    for key in ("source", "file", "path", "filename"):
                        if meta.get(key):
                            src_name = os.path.basename(str(meta[key]))
                            break
                    header = f"**Source {i}** â€” {page_label}" + (f" â€” {src_name}" if src_name else "")
                    st.markdown(header)
                    st.caption((doc.page_content or "")[:600] + ("..." if len(doc.page_content or "") > 600 else ""))

    st.divider()

    # ----------------- Mark Correctness (after answer) -----------------
    st.subheader("Mark Correctness")
    col1, col2 = st.columns([1, 2])
    with col1:
        correctness = st.radio("Is the answer correct?", ["Y", "N", "Skip"], index=2, horizontal=True)
    with col2:
        save_btn = st.button("Save to Log")

    if save_btn:
        ensure_log_header(LOG_FILE)
        row = [
            last["question"],
            last["method"],
            last["answer"],
            "" if last["confidence"] is None else f"{last['confidence']:.4f}",
            f"{last['time_s']:.2f}",
            "" if correctness == "Skip" else correctness,
        ]
        with open(LOG_FILE, mode="a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(row)
        st.success("Logged âœ…")
